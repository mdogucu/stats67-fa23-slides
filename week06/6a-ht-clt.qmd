---
title: "Introduction to Statistical Inference"
author: "Dr. Mine Dogucu"
format: 
  revealjs:
    footer: "[stats4cs.com](https://stats4cs.com)"
    slide-number: true
    incremental: true
    theme: ["../templates/slide-style.scss"]
    logo: "https://www.stats4cs.com/img/logo.png"
    title-slide-attributes: 
      data-background-image: "https://www.stats4cs.com/img/logo.png"
      data-background-size: 5%
      data-background-position: 50% 85%
    include-after-body: "../templates/clean_title_page.html"
---

```{r}
#| echo: false
options(scipen=0)
library(tidyverse)
library(fivethirtyeight)
library(scales)

set.seed(84735)
```

# Hypotheses Testing

## Review of Notation

<table align ="center">

<thead>
<th> </th>
<th>Sample Statistic</th>
<th>Population Parameter</th>
</thead>

<tr>
<td>Mean</td>
<td> x&#772; </td>
<td> &mu;</td>

</tr>

<tr>
<td> Standard Deviation </td>
<td> s </td>
<td> &sigma;</td>

</tr>

<tr>
<td> Variance </td>
<td> s<sup>2</sup> </td>
<td> &sigma;<sup>2</sup></td>

</tr>

<tr> 
<td>Proportion</td>
<td>p</td>
<td>&pi;</td>

</tr>


</table>

##



In statistics, we are interested in making an inference about population parameters using sample statistics. We set and test hypotheses about the population. 

## 

:::{.font75}

null means zero(which represents nothingness)

:::



## Research Question

Are there any pink cows in the world?



## Hypotheses

**Null** hypothesis: There are __no__ pink cows in the world.  

**Alternative** hypothesis: There is a pink cow in the world.



## Hypothesis Testing Procedure

We go looking for evidence against the null. 

- If we find any evidence against the null (a single pink cow) then we can conclude the null is false. We say we **reject the null** hypothesis.

- If we do not find any evidence against the null (a single pink cow) then **we fail to reject the null**. We can keep searching for more evidence against the null (i.e. continue looking for a pink cow). We will never be able to say the null is true so we never accept the null. All we can do is keep looking for a pink cow.

## Research Question

Are there any black cows in the world?


## Hypotheses

**Null** hypothesis: There are __no__ black cows in the world.

**Alternative** hypothesis: There is a black cow in the world.

##

```{r echo = FALSE, fig.align = 'center', out.width="40%"}
library(emojifont)
library(ggplot2)

ggplot() + geom_emoji("cow", color='black') + theme_void()
```

When we see a black cow, we **reject** the null hypothesis and conclude that there is a black cow in the world. 

##

```{r}
knitr::include_graphics('img/tweet.png', error = FALSE)
```



## Research Question

Is there a foreign object in the cat's body?



## Hypothesis Testing

**Null** hypothesis: There is __no__ foreign object in the cat's body.

**Alternative** hypothesis: There  is a foreign object in the cat's body.


## Collect Evidence

X-ray


## Conclusion and Decision


X-ray does not show any foreign object. 


- Fail to reject the null hypothesis.
- We __cannot__ conclude the null hypothesis is true. We __cannot__ accept the null hypothesis.


## Example


**Null** hypothesis: There is **no** problem with my cell phone.

**Alternative** hypothesis: There is a problem with my cell phone.


## Collect Evidence

- Check if the screen is broken.

. . .

- Check if the battery life is too short.

. . .

- Check if the response times of apps are long.

. . .

- ...


## Conclusion and Decision

No problems were detected.

- Fail to reject the null hypothesis. 

. . .

- You __cannot__ conclude that there is no problem with the cell phone.

. . .

- You can state that there were no problems detected (i.e. there was no evidence against the null).


## Remember

- Null hypothesis is always about nothing: **no** pink cow, **no** effect, **no** difference etc.

. . .

- We __never__ accept the null hypothesis. We either reject it or fail to reject it.

. . .

- In frequentist statistics, we always start hypotheses testing with the assumption that the null hypothesis is true and try to find evidence against it. 


# Writing Hypotheses with Notation

##

::: {.font75}

If there was no variance there would be no need for statistics.

:::

## What if?

- We want to understand average number of sleep Irvine residents get.  What if everyone in Irvine slept 8 hours every night? (`sleep` = {8, 8,..., 8})



- We want to predict who will graduate college. What if everyone graduated college? (`graduate` = {TRUE, TRUE,..., TRUE})

##

- We want to understand if Android users spend more time on their phones when compared to iOS users. What if everyone spent 3 hours per day on their phones? (`time` = {3, 3,..., 3}, `os` = {Android, Android, .... iOS})


- We want to understand, if birth height and weight are positively associated in babies. What if every baby was 7.5 lbs? (`weight` = {7.5, 7.5,..., 7.5}, `height` = {20, 22,..., 18})

##

In all these fake scenarios there would be no **variance** in `sleep`, `graduate`, `time`, `weight`. These variables would all be constants thus would not even be a **vari**able.

:::{.font50}

Things vary. We use statistics in research studies to understand **how** variables vary and often we want to know **how** they **covary** with other variables. 

:::

##

To make the connection between research questions of studies and statistics, we will take small steps and begin with writing hypotheses using notation.

##

`r fontawesome::fa(name = "search", fill = "#e56646")` **Research Question** Do UCI students sleep on average 8 hours on a typical night? 


. . .

`r fontawesome::fa(name = "table", fill = "#e56646")` **Variable** `sleep` (8,7,9,7.5, ...)

. . .

`r fontawesome::fa(name = "language", fill = "#e56646")` **Research Question Using Notation** $\mu \stackrel{?}{=} 8$

. . .

**Hypotheses** 

:::{.pull-left}
$H_0 : \mu = 8$  
$H_A : \mu \neq 8$

::: 

:::{.pull-right}
$H_0 : \mu - 8 = 0$  
$H_A : \mu - 8 \neq 0$ 
:::

. . .

The parameter we want to infer about is **a single mean**.

##

::: {.callout-tip }

If you want to type math notation correctly on Gradescope or Quarto out correctly as $\mu$ then you can write 

```{r eval = FALSE}
$$\mu$$
```

The double dollar signs at the beginning and at the end let Gradescope know that you are writing a math equation.

:::

##

`r fontawesome::fa(name = "search", fill = "#e56646")` **Research Question** Do the majority of Americans approve allowing DACA immigrants to become citizens?

. . .

`r fontawesome::fa(name = "table", fill = "#e56646")` **Variable** `approve` (yes, yes, yes, no, yes, no, no)

. . .

`r fontawesome::fa(name = "language", fill = "#e56646")` **Research Question Using Notation** $\pi \stackrel{?}{>} 0.5$ 

. . .

**Hypotheses** 

$H_0: \pi = 0.5$  
$H_A: \pi \neq 0.5$

. . .

The parameter we want to infer about is **a single proportion**.

##

`r fontawesome::fa(name = "search", fill = "#e56646")` **Research Question** Is California March 2020 unemployment rate different than US March 2020 unemployment rate which is at 4.4%?

. . .

`r fontawesome::fa(name = "table", fill = "#e56646")` **Variable** `unemployed_CA` (no, no, yes, no, yes, no, no...)

. . .

`r fontawesome::fa(name = "language", fill = "#e56646")` **Research Question Using Notation** $\pi \stackrel{?}{=} 0.044$

. . .

**Hypotheses**

$$H_0:\pi= 0.044$$  $$H_A: \pi \neq 0.044$$

. . .


The parameter we want to infer about is **a single proportion**.

## 

`r fontawesome::fa(name = "search", fill = "#e56646")` **Research Question** Are there more STEM majors at UCI than non-STEM majors?

. . .

`r fontawesome::fa(name = "table", fill = "#e56646")` **Variable** `STEM` (TRUE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE...)

. . .

`r fontawesome::fa(name = "language", fill = "#e56646")` **Research Question Using Notation** $\pi_{STEM} \stackrel{?}{>} 0.5$

. . .

**Hypotheses**

$$H_0: \pi = 0.5$$ $$H_A: \pi \neq 0.5$$

. . .

The parameter we want to infer about is **a single proportion**.

##

`r fontawesome::fa(name = "search", fill = "#e56646")` **RQ** Do STEM (s) majors have higher or lower (different) income after graduation when compared to non-STEM (n) majors?

. . .

`r fontawesome::fa(name = "table", fill = "#e56646")` **Variables** explanatory: `STEM` (TRUE, FALSE, FALSE, TRUE,...)  
response: `income`(40000, 20000, 65490, 115000,...)

. . .

`r fontawesome::fa(name = "language", fill = "#e56646")` **Research Question Using Notation** $\mu_{s} \stackrel{?}{=} \mu_{n}$ or $\mu_{s} - \mu_{n}  \stackrel{?}{=}0$ 

. . .

**Hypotheses**

:::{.pull-left}
$$H_0:\mu_{s} = \mu_{n}$$  $$H_A:\mu_{s} \neq \mu_{n}$$
:::

:::{.pull-right}
$$H_0:\mu_{s} - \mu_{n} = 0$$  $$H_A:\mu_{s} - \mu_{n} \neq 0$$
:::

. . .

We want to infer about **difference of two means**.

##

`r fontawesome::fa(name = "search", fill = "#e56646")` **RQ** Do Democrats and Republicans approve legal abortion at same rates?

. . .

`r fontawesome::fa(name = "table", fill = "#e56646")` **Variables** explanatory: `party` (D, D, R, R,...)  
response: `approve`(TRUE, FALSE, FALSE, TRUE,...)

. . .

`r fontawesome::fa(name = "language", fill = "#e56646")` **Research Question Using Notation** $\pi_{d} \stackrel{?}{=} \pi_{r}$ or $\pi_{d} -  \pi_{r} \stackrel{?}{=}0$ 

. . .

**Hypotheses**

$H_0:\pi_{d} = \pi_{r}$  
$H_A:\pi_{d} \neq \pi_{r}$
. . .

We want to infer about **difference of two proportions**.


##


<div align="center">

|                               | Parameter of Interest | Response              |Explanatory            |
|-------------------------------|-----------------------|-----------------------|-----------------------|
| Single Mean                   | $\mu$                 | Numeric               |
| Difference of Two Means       | $\mu_1 - \mu_2$       | Numeric               |Binary                 |
| Single Proportion             | $\pi$                 | Binary                |
| Difference of Two Proportions | $\pi_1 - \pi_2$       | Binary                |Binary                 |


A categorical variable with two levels is called a __binary__ variable.

##

Later on we will also learn

<div align = "center">

| Parameter of Interest | Response              |Explanatory                |
|-----------------------|-----------------------|-----------------------    |
| $\beta_1$             | Numeric               | Categorical and/or Numeric|




# Central Limit Theorem

## Normal Distribution

## Parameters of a normal distribution $N(\mu, \sigma^2$


```{r echo = FALSE, fig.align='center'}
p1 <- 
  ggplot(data = data.frame(x = c(0, 200)), 
         aes(x)) +
  stat_function(fun = dnorm, n = 1001, args = list(mean = 100, sd = 15)) + 
  ylab("") +
  labs(title = bquote(N(100, 15^2)))

p2 <- 
  ggplot(data = data.frame(x = c(0, 200)), 
         aes(x)) +
  stat_function(fun = dnorm, n = 1001, args = list(mean = 100, sd = 30)) + 
  ylab("") +
  labs(title = bquote(N(100, 30^2)))

p3 <- 
  ggplot(data = data.frame(x = c(0, 200)), 
         aes(x)) +
  stat_function(fun = dnorm, n = 1001, args = list(mean = 90, sd = 15)) + 
  ylab("") +
  labs(title = bquote(N(90, 15^2)))


p4 <- 
  ggplot(data = data.frame(x = c(0, 200)), 
         aes(x)) +
  stat_function(fun = dnorm, n = 1001, args = list(mean = 90, sd = 30)) + 
  ylab("") +
  labs(title = bquote(N(90, 30^2)))

gridExtra::grid.arrange(p1, p2, p3, p4, ncol = 2, nrow = 2)
```


## Data

```{r}
#| echo: false
lapd <- read_csv("data/lapd_2018.csv") %>% 
  janitor::clean_names() %>% 
  select(base_pay)
```

We will be using payroll data from Los Angeles Police Department (LAPD) from 2018.


```{r echo = TRUE}
glimpse(lapd)
```

## Population Distribution

```{r}
#| echo: false
lapd %>% 
  ggplot(aes(x = base_pay)) +
  geom_histogram(binwidth = 5000) +
  scale_x_continuous(labels = comma) +
  theme(text = element_text(size = 20)) 
  
```

## Population Mean

We have data on everyone who worked for LAPD in the year 2018. So the distribution we just looked at is a population distribution. We can go ahead and calculate the population mean ( $\mu$ ).

```{r}
summarize(lapd, mean(base_pay))
```

## Population Standard Deviation

We can calculate the population standard deviation ( $\sigma$ ).

```{r}
summarize(lapd, sd(base_pay))
```

##

What if we did not have access to all this data? What would we do?

. . .

Rely on a sample!

##

```{r}
#| echo: false
pop_mean <-  mean(lapd$base_pay)
```

##

Let's assume we went ahead and took a (random) sample of LAPD staff and asked their salary information (and they report to us truthfully) and calculated a mean, would we find a mean of 85149.05? Why, why not?

##

Let's pretend we have never seen the data and we do not know the population parameter $\mu$. In fact this is usually what happens in real life. We do not have the population information but we do want to know a population __parameter__ (does not necessarily have to be the mean).

. . .
If we took a sample and calculated the sample mean, we would name this __point estimate__ of the parameter. 




|                               | Parameter of Interest | Point Estimate / Sample Statistic |
|-------------------------------|-----------------------|-----------------------------------|
| Mean                          | $\mu$                 | $\bar x$                          |
| Difference of Two Means       | $\mu_1 - \mu_2$       | $\bar x_1 - \bar x_2$             |
| Proportion                    | $\pi$                 | $p$                               |
| Difference of Two Proportions | $\pi_1 - \pi_2$       | $p_1 - p_2$                       |


## First Sample

We would like to know about $\mu$ but we cannot access the whole population.

A researcher takes a random sample of 20 LAPD staff and ask them about their base pay.

. . .

```{r}
sample_1 <- lapd %>% 
  sample_n(20) 
sample_1$base_pay
```

. . . 

**Mean of first sample**, $\bar x_1$ = 

```{r}
mean(sample_1$base_pay)
```

## Mean of second sample

$\bar x_2$ = 

```{r}
sample_2 <- lapd %>% 
  sample_n(20) %>% 
  select(base_pay)

mean(sample_2$base_pay)
```


## Mean of third sample

$\bar x_3$ = 

```{r}
sample_3 <- lapd %>% 
  sample_n(20) %>% 
  select(base_pay)

mean(sample_3$base_pay)
```

## 
We could do this over and over again. Don't you worry! I did it.

I have taken 10,000 samples of size 200 (sample size of 20 is just too small) and calculated their mean. The following slide shows the distribution of the **sample means**.

## Sampling Distribution of the Mean

```{r warning = FALSE, cache = TRUE}
set.seed(123)
sample_means <-vector()

for (i in 1:10000){
    sample_means <- c(sample_means, mean(sample_n(lapd, 200)$base_pay))
}

sample_means_data <- data.frame(sample_means = sample_means)

```

```{r warning = FALSE, message = FALSE}
sample_means_data %>% 
  ggplot(aes(x = sample_means)) +
  geom_histogram() +
  labs(x = "Sample Means") +
  scale_x_continuous(labels = comma) +
  theme(text = element_text(size = 20))  +
    geom_text(x = 0, y = 0, label = "bar(x)", parse=T)
```

## Sampling Distribution of the Mean

```{r warning = FALSE, message = FALSE}
population_mean <- mean(lapd$base_pay)

sample_means_data %>% 
  ggplot(aes(x = sample_means)) +
  geom_histogram() +
  labs(x = "Sample Means") +
  scale_x_continuous(labels = comma) +
  theme(text = element_text(size = 20))  +
    geom_text(x = 0, y = 0, label = "bar(x)", parse=T) +
  geom_vline(xintercept = population_mean)
```

##

When certain conditions are met then:


$$\bar x \sim \text{approximately }N( \mu, \frac{\sigma^2}{n})$$

. . .

$$(\bar x_1 - \bar x_2) \sim \text{approximately } N(\mu_1 - \mu_2, \frac{\sigma_1^2}{n_1}+ \frac{\sigma_2^2}{n_2})$$

. . .

$$p \sim  \text{approximately } N(\pi,  \frac{\pi(1-\pi)}{n})$$

. . .

$$(p_1 - p_2) \sim \text{approximately } N((\pi_1 - \pi_2),  {\frac{\pi_1(1-\pi_1)}{n_1} + \frac{\pi_2(1-\pi_2)}{n_2}})$$


## Central Limit Theorem (CLT)

If certain conditions are met, the sampling distribution will be normally distributed with a mean equal to the population parameter. The standard deviation will be inversely proportional to the square root of the sample size. 

. . .

We will learn the conditions in the upcoming lectures.

. . .

Moving forward we will use CLT to make __inference__ about population parameters using sample statistics. 

## Take-Away Messages

- Sample statistics are point estimates. They are not the same thing as population parameters. 

. . .

- Point estimates can vary from sample to sample. Sampling distribution captures this variance. 

. . .

- Sampling distribution is never observed. 




